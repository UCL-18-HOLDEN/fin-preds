{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Company Price TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File S&P500_component_data/S&P500_company_components_prices.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-68e280855102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'S&P500_component_data/S&P500_company_components_prices.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcommissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'full_timeseries_orders.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samuelholden/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samuelholden/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samuelholden/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samuelholden/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samuelholden/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File S&P500_component_data/S&P500_company_components_prices.csv does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('S&P500_component_data/S&P500_company_components_prices.csv')\n",
    "\n",
    "commissions = pd.read_csv('full_timeseries_orders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_mapping = pd.read_csv('s&p500_conm_and_generic.csv')[['conm','generic']]\n",
    "names_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_NAME = names_mapping['conm'].loc[0]\n",
    "GENERIC_NAME = names_mapping['generic'].loc[0]\n",
    "#GENERIC_NAME = 'amazon'\n",
    "\n",
    "df1 = df[df['conm']==COMPANY_NAME]\n",
    "df1['date']= pd.to_datetime(df1['datadate'],format='%Y%m%d')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align with commissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_regready(commissions,df1):\n",
    "    commissions_nord = commissions[commissions['generic_name']==GENERIC_NAME]\n",
    "\n",
    "    commissions_nord.drop('generic_name',axis=1,inplace=True)\n",
    "    commissions_nord=commissions_nord.transpose()\n",
    "    print(commissions_nord)\n",
    "    commissions_nord.reset_index(inplace=True)\n",
    "    commissions_nord=commissions_nord.rename(columns={9:'order_tot','index':'date'}) #The column number becomes the column name upon transpose (currently changed manually at each aggregation)\n",
    "    commissions_nord['date'] = pd.to_datetime(commissions_nord['date'],format='%d/%m/%y')\n",
    "    \n",
    "    #for etsy (otherwise remove)\n",
    "    #commissions_nord = commissions_nord[commissions_nord['date']>pd.datetime(2015,05,01)]\n",
    "    #commissions_nord = commissions_nord.reset_index(drop=True)\n",
    "    \n",
    "    comms_dates = commissions_nord['date'] + pd.DateOffset(1)\n",
    "    \n",
    "    cols = df1.columns\n",
    "    weekly_prices = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for date in comms_dates:\n",
    "        a = df1[df1['date']==date]\n",
    "        while a.empty:\n",
    "            a = df1[df1['date']==date+pd.DateOffset(days=1)]\n",
    "        a['sunday_date'] = date - pd.DateOffset(days=1)\n",
    "        weekly_prices=weekly_prices.append(a)\n",
    "        \n",
    "    weekly_prices.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    weekly_prices = weekly_prices.rename(columns={'prccd':'Close','prcod':'Open'})\n",
    "    \n",
    "    weekly_prices1 = weekly_prices\n",
    "\n",
    "    weekly_prices1['open_next_wk'] = weekly_prices1['Open'].shift(-1)\n",
    "    weekly_prices1['weekly_ret'] = weekly_prices1['open_next_wk'] - weekly_prices1['Open']\n",
    "    weekly_prices1['weekly_pct'] = weekly_prices1['weekly_ret']/weekly_prices1['Open']\n",
    "    weekly_prices1['sunday_date_beginning'] = weekly_prices1['sunday_date']\n",
    "    \n",
    "    weekly_prices1 = weekly_prices1[['conm','sunday_date_beginning','Open','weekly_ret','weekly_pct']]\n",
    "    \n",
    "    new_df = []\n",
    "\n",
    "    for idx in range(6,177): #177 if not ETSY\n",
    "        most_recent_comm = []\n",
    "        for i in range(6):\n",
    "            #print commissions_nord['order_tot']\n",
    "            most_recent_comm.insert(0,commissions_nord['order_tot'][idx-i])\n",
    "        most_recent_comm.append(weekly_prices1['sunday_date_beginning'][idx])\n",
    "        new_df.append(most_recent_comm)\n",
    "        \n",
    "    new_df = pd.DataFrame(new_df,columns=['six','five','four','three','two','one','sunday_beginning'])\n",
    "    \n",
    "    merged = new_df.merge(weekly_prices1,how='left',left_on='sunday_beginning',right_on='sunday_date_beginning')\n",
    "    \n",
    "    merged['monthly_ret']=0.0\n",
    "    for idx2 in range(168): #168 if not ETSY\n",
    "        merged['monthly_ret'][idx2] = merged['weekly_ret'][idx2]+merged['weekly_ret'][idx2+1]+merged['weekly_ret'][idx2+2]+merged['weekly_ret'][idx2+3]\n",
    "    merged['monthly_pct_ret'] = merged['monthly_ret']/merged['Open']\n",
    "        \n",
    "    merged['is_DEC'] = merged['sunday_beginning'].dt.month==12\n",
    "    merged['is_NOV'] = merged['sunday_beginning'].dt.month==11\n",
    "        \n",
    "    return merged\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = timeseries_regready(commissions,df1)\n",
    "merged = merged[:-5]\n",
    "merged['month'] = 0\n",
    "merged['month'] = merged['sunday_beginning'].map(lambda x:x.month)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_average_month = merged.groupby(by='month',as_index=False).mean()\n",
    "merged_average_month = merged_average_month[['month','one','two','three','four','five','six']]\n",
    "merged_average_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_average_month.rename(columns={'one':'one_avg','two':'two_avg','three':'three_avg','four':'four_avg',\n",
    "                                     'five':'five_avg','six':'six_avg'},inplace=True)\n",
    "\n",
    "merged_average_month\n",
    "\n",
    "std_df2 = pd.merge(merged,merged_average_month,how='left',left_on='month',right_on='month')\n",
    "\n",
    "std_df2['one'] = std_df2['one']/std_df2['one_avg']\n",
    "std_df2['two'] = std_df2['two']/std_df2['two_avg']\n",
    "std_df2['three'] = std_df2['three']/std_df2['three_avg']\n",
    "std_df2['four'] = std_df2['four']/std_df2['four_avg']\n",
    "std_df2['five'] = std_df2['five']/std_df2['five_avg']\n",
    "std_df2['six'] = std_df2['six']/std_df2['six_avg']\n",
    "\n",
    "std_df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_df = merged.copy()\n",
    "#std_df2 = merged.copy()\n",
    "#\n",
    "#lag=52\n",
    "#\n",
    "#for idx,row in enumerate(std_df['sunday_beginning']):\n",
    "#    if idx>=lag:\n",
    "#        std_df2['one'][idx] = std_df['one'][idx]/std_df['one'][idx-lag]\n",
    "#        std_df2['two'][idx] = std_df['two'][idx]/std_df['two'][idx-lag]\n",
    "#        std_df2['three'][idx] = std_df['three'][idx]/std_df['three'][idx-lag]\n",
    "#        std_df2['four'][idx] = std_df['four'][idx]/std_df['four'][idx-lag]\n",
    "#        std_df2['five'][idx] = std_df['five'][idx]/std_df['five'][idx-lag]\n",
    "#        std_df2['six'][idx] = std_df['six'][idx]/std_df['six'][idx-lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_short = COMPANY_NAME.split()[0]\n",
    "comp_short = comp_short.lower()\n",
    "std_df2.to_csv('reg_ready_'+comp_short+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
